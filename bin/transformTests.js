/*
Token transform unit test system

Purpose:
 During the porting of Parsoid to PHP, we need a system to capture
 and replay Javascript Parsoid token handler behavior and performance
 so we can duplicate the functionality and verify adequate performance.

 The transformerTest.js program works in concert with Parsoid and special
 capabilities added to the TokenTransformationManager.js file which
 now has token transformer test generation capabilities that produce test
 files from existing wiki pages or any wikitext. The Parsoid generated tests
 contain the specific handler name chosen for generation and the pipeline
 that was associated with the transformation execution. The pipeline ID
 is used by transfoermTest.js to properly order the replaying of the
 transformers input and output sequencing for validation.

 Manually written tests are supported and use a slightly different format
 which more closely resembles parserTest.txt and allows the test writer
 to identify each test with a unique description and combine tests
 for different token handlers in the same file, though only one handlers
 code can be validated and performance timed.

Technical details:
 The test validator and handler runtime emulates the normal
 Parsoid token transform manager behavior and handles tests sequences that
 were generated by multiple pipelines and uses the pipeline ID to call
 the transformers in sorted execution order to deal with parsoids
 execution order not completing each pipelined sequence in order.
 The system utilizes the transformers initialization code to install handler
 functions in a generalized way and run the test without specific
 transformer bindings.

 To create a test from an existing wikitext page, run the following
 commands, for example:
 $ node bin/parse.js --genTest QuoteTransformer,quoteTestFile.txt --pageName 'skating' < /dev/null > /dev/null

 For command line options and required parameters, type:
 $ node bin/transformerTest.js --help

 An example command line to validate and performance test the 'skating'
 wikipage created as a QuoteTransformer test:
 $ node bin/transformTests.js --log --QuoteTransformer --inputFile quoteTestFile.txt
*/

'use strict';

var defines = require('../lib/wt2html/parser.defines.js');
var QuoteTransformer = require('../lib/wt2html/tt/QuoteTransformer.js').QuoteTransformer;
var ListHandler = require('../lib/wt2html/tt/ListHandler.js').ListHandler;
var ParagraphWrapper = require('../lib/wt2html/tt/ParagraphWrapper.js').ParagraphWrapper;
var PreHandler = require('../lib/wt2html/tt/PreHandler.js').PreHandler;
var TokenStreamPatcher = require('../lib/wt2html/tt/TokenStreamPatcher.js').TokenStreamPatcher;
var BehaviorSwitchHandler = require('../lib/wt2html/tt/BehaviorSwitchHandler.js').BehaviorSwitchHandler;
var SanitizerHandler = require('../lib/wt2html/tt/Sanitizer.js').SanitizerHandler;
var Util = require('../lib/utils/Util.js').Util;
var yargs = require('yargs');
var fs = require('fs');

var cachedState = false;
var cachedTestLines = '';
var cachedPipeLines = '';
var cachedPipeLinesLength = [];

function MockTTM(env, options) {
	this.env = env;
	this.pipelineId = 0;
	this.options = options;
	this.defaultTransformers = [];	// any transforms
	this.tokenTransformers   = {};	// non-any transforms
	this.tokenTime = 0; // floating-point value (# ms)
}

MockTTM.prototype.log = function() {
	var output = arguments[0];
	for (var index = 1; index < arguments.length; index++) {
		if (typeof arguments[index] === 'function') {
			output = output + ' ' + arguments[index]();
		} else {
			output = output + ' ' + arguments[index];
		}
	}
	console.log(output);
};

// Map of: token constructor ==> transfomer type
// Used for returning active transformers for a token
MockTTM.tkConstructorToTkTypeMap = {
	"String": "text",
	"NlTk": "newline",
	"CommentTk": "comment",
	"EOFTk": "end",
	"TagTk": "tag",
	"EndTagTk": "tag",
	"SelfclosingTagTk": "tag",
};

function tokenTransformersKey(tkType, tagName) {
	return (tkType === 'tag') ? "tag:" + tagName : tkType;
}

MockTTM.prototype._cmpTransformations = function(a, b) {
	return a.rank - b.rank;
};

MockTTM.prototype.addTransform = function(transformation, debugName, rank, type, name) {

	var t = {
		rank: rank,
		name: debugName,
		transform: transformation
	};

	if (type === 'any') {
		// Record the any transformation
		this.defaultTransformers.push(t);
	} else {
		var key = tokenTransformersKey(type, name);
		var tArray = this.tokenTransformers[key];
		if (!tArray) {
			tArray = this.tokenTransformers[key] = [];
		}

		// assure no duplicate transformers
		console.assert(tArray.every(function(tr) {
			return tr.rank !== t.rank;
		}), "Trying to add a duplicate transformer: " + t.name);

		tArray.push(t);
		tArray.sort(this._cmpTransformations);
	}
};

function removeMatchingTransform(transformers, rank) {
	var i = 0;
	var n = transformers.length;
	while (i < n && rank !== transformers[i].rank) {
		i++;
	}
	transformers.splice(i, 1);
}

MockTTM.prototype.removeTransform = function(rank, type, name) {
	if (type === 'any') {
		// Remove from default transformers
		removeMatchingTransform(this.defaultTransformers, rank);
	} else {
		var key = tokenTransformersKey(type, name);
		var tArray = this.tokenTransformers[key];
		if (tArray) {
			removeMatchingTransform(tArray, rank);
		}
	}
};

MockTTM.prototype.getTransforms = function(token, minRank) {
	var tkType = MockTTM.tkConstructorToTkTypeMap[token.constructor.name];
	var key = tokenTransformersKey(tkType, token.name);
	var tts = this.tokenTransformers[key] || [];
	if (this.defaultTransformers.length > 0) {
		tts = tts.concat(this.defaultTransformers);
		tts.sort(this._cmpTransformations);
	}

	var i = 0;
	if (minRank !== undefined) {
		// skip transforms <= minRank
		while (i < tts.length && tts[i].rank <= minRank) {
			i += 1;
		}
	}
	return { first: i, transforms: tts, empty: i >= tts.length };
};

// Use the TokenTransformManager.js guts (extracted essential functionality)
// to dispatch each token to the registered token transform function
MockTTM.prototype.ProcessTestFile = function(commandLine) {
	var transformerName;
	var testName;
	var result;
	var testFile;
	var testLines;

	if (commandLine.timingMode) {
		if (cachedState === false) {
			cachedState = true;
			testFile = fs.readFileSync(commandLine.inputFile, 'utf8');
			testLines = testFile.split('\n');
			cachedTestLines = testLines;
		} else {
			testLines = cachedTestLines;
		}
	} else {
		testFile = fs.readFileSync(commandLine.inputFile, 'utf8');
		testLines = testFile.split('\n');
	}

	for (var index = 0; index < testLines.length; index++) {
		var line = testLines[index];
		switch (line.charAt(0)) {
			case '#':	// comment line
			case ' ':	// blank character at start of line
			case '':	// empty line
				break;
			case ':':
				transformerName = line.substr(2);
				break;
			case '!':	// start of test with name
				testName = line.substr(2);
				break;
			case '[':	// desired result json string for test result verification
				if (result !== undefined && result.tokens.length !== 0) {
					var stringResult = JSON.stringify(result.tokens);
					if (stringResult === line) {
						if (!commandLine.timingMode) {
							console.log(testName + ' ==> passed\n');
						}
					} else {
						console.log(testName + ' ==> failed');
						console.log('line to debug => ' + line);
						console.log('result line ===> ' + stringResult + "\n");
					}
				}
				result = undefined;
				break;
			case '{':
			default:
				if (!result) {
					result = { tokens: [] };
				}
				var token = JSON.parse(line);
				if (token.constructor !== String) {	// cast object to token type
					console.assert(defines[token.type] !== undefined, "Incorrect type [" + token.type + "] specified in test file\n");
					token.prototype = token.constructor = defines[token.type];
				}
				var s = process.hrtime();
				var res = { token: token };
				var ts = this.getTransforms(token, 2.0);
				// Push the token through the transformations till it morphs
				var j = ts.first;
				var numTransforms = ts.transforms.length;
				while (j < numTransforms && (token === res.token)) {
					var transformer = ts.transforms[j];
					if (transformerName === transformer.name.substr(0, transformerName.length)) {
						// Transform the token.
						res = transformer.transform(token, this);
						if (res.tokens) {
							result.tokens = result.tokens.concat(res.tokens);
						} else if (res.token && res.token !== token) {
							result.tokens = result.tokens.concat(res.token);
						}
					}
					j++;
				}
				var diff = process.hrtime(s);
				this.tokenTime += (diff[0]*1e9 + diff[1]) / 1000000; // # milliseconds
				break;
		}
	}
};

// Because tokens are processed in pipelines which can execute out of
// order, the unit test system creates an array of arrays to hold
// the pipeline ID which was used to process each token.
// The ProcessWikitextFile function uses the pipeline IDs to ensure
// that all token processing for each pipeline occurs in order to completion.
function CreatePipelines(lines) {
	var numberOfTextLines = lines.length;
	var maxPipelineID = 0;
	var LineToPipeMap = new Array(numberOfTextLines);
	var i;
	var pipe;
	for (i = 0; i < numberOfTextLines; ++i) {
		pipe = parseInt(lines[i].substr(0, 4), 10);	// pipeline ID's should not exceed 9999
		if (!isNaN(pipe)) {
			if (maxPipelineID < pipe) {
				maxPipelineID = pipe;
			}
		}
		LineToPipeMap[i] = pipe;
	}
	var pipelines = new Array(maxPipelineID + 1);
	for (i = 0; i < numberOfTextLines; ++i) {
		pipe = LineToPipeMap[i];
		if (!isNaN(pipe)) {
			if (pipelines[pipe] === undefined) {
				pipelines[pipe] = [i];
			} else {
				pipelines[pipe].push(i);
			}
		}
	}
	return pipelines;
}

// Use the TokenTransformManager.js guts (extracted essential functionality)
// to dispatch each token to the registered token transform function
MockTTM.prototype.ProcessWikitextFile = function(tokenTransformer, commandLine) {
	var result;
	var testFile;
	var testLines;
	var pipeLines;
	var pipeLinesLength;

	if (commandLine.timingMode) {
		if (cachedState === false) {
			cachedState = true;
			testFile = fs.readFileSync(commandLine.inputFile, 'utf8');
			testLines = testFile.split('\n');
			pipeLines = CreatePipelines(testLines);
			pipeLinesLength = pipeLines.length;
			cachedTestLines = testLines;
			cachedPipeLines = pipeLines;
			cachedPipeLinesLength = pipeLinesLength;
		} else {
			testLines = cachedTestLines;
			pipeLines = cachedPipeLines;
			pipeLinesLength = cachedPipeLinesLength;
		}
	} else {
		testFile = fs.readFileSync(commandLine.inputFile, 'utf8');
		testLines = testFile.split('\n');
		pipeLines = CreatePipelines(testLines);
		pipeLinesLength = pipeLines.length;
	}

	for (var index = 0; index < pipeLinesLength; index++) {
		if (pipeLines[index] !== undefined) {
			tokenTransformer.manager.pipelineId = index;
			var pipeLength = pipeLines[index].length;
			for (var element = 0; element < pipeLength; element++) {
				var line = testLines[(pipeLines[index])[element]].substr(36);
				switch (line.charAt(0)) {
					case '[':	// desired result json string for test result verification
						var stringResult = JSON.stringify(result.tokens);
						if (stringResult === line) {
							if (!commandLine.timingMode) {
								console.log('line ' + ((pipeLines[index])[element] + 1) + ' ==> passed\n');
							}
						} else {
							console.log('line ' + ((pipeLines[index])[element] + 1) + ' ==> failed');
							console.log('line to debug => ' + line);
							console.log('result line ===> ' + stringResult + "\n");
						}
						result = undefined;
						break;
					case '{':
					default:
						if (!result) {
							result = { tokens: [] };
						}
						var token = JSON.parse(line);
						if (token.constructor !== String) {	// cast object to token type
							console.assert(defines[token.type] !== undefined, "Incorrect type [" + token.type + "] specified in test file\n");
							token.prototype = token.constructor = defines[token.type];
						}
						var s = process.hrtime();
						var ts = this.getTransforms(token, 2.0);
						var res = { token: token };

						// Push the token through the transformations till it morphs
						var j = ts.first;
						var numTransforms = ts.transforms.length;
						while (j < numTransforms && (token === res.token)) {
							var transformer = ts.transforms[j];
							// Transform the token.
							res = transformer.transform(token, this);
							if (res.tokens) {
								result.tokens = result.tokens.concat(res.tokens);
							} else if (res.token && res.token !== token) {
								result.tokens = result.tokens.concat(res.token);
							}
							j++;
						}
						var diff = process.hrtime(s);
						this.tokenTime += (diff[0]*1e9 + diff[1]) / 1000000; // # milliseconds
						break;
				}
			}
		}
	}
};

MockTTM.prototype.unitTest = function(tokenTransformer, commandLine) {
	if (!commandLine.timingMode) {
		console.log('Starting stand alone unit test running file ' + commandLine.inputFile + '\n');
	}
	tokenTransformer.manager.ProcessTestFile(commandLine);
	if (!commandLine.timingMode) {
		console.log('Ending stand alone unit test running file ' + commandLine.inputFile + '\n');
	}
};

MockTTM.prototype.wikitextTest = function(tokenTransformer, commandLine) {
	if (!commandLine.timingMode) {
		console.log('Starting stand alone wikitext test running file ' + commandLine.inputFile + '\n');
	}
	tokenTransformer.manager.ProcessWikitextFile(tokenTransformer, commandLine);
	if (!commandLine.timingMode) {
		console.log('Ending stand alone wikitext test running file ' + commandLine.inputFile + '\n');
	}
};

var opts = yargs.usage('Usage: $0 [options] --TransformerName --inputFile /path/filename', {
	help: {
		description: [
			'transformTest.js supports parsoid generated and manually created',
			'test validation. See tests/transformTests.txt to examine and run',
			'a manual test. The --manual flag is optional defaulting to parsoid',
			'generated test format (which has machine generated context to aid',
			'in debugging. The --timingMode flag disables console output and',
			'caches the file IO and related text processing and then iterates',
			'the test 10000 times',
			' The --log option provides additional debug content.',
			'Current handlers supported are: QuoteTransformer, ListHandler',
			'ParagraphWrapper, PreHandler.',
			'TokenStreamPatcher, BehaviorSwitchHandler and SanitizerHandler are',
			'partially implemented, being debugged but not yet usable.\n'
		].join(' ')
	},
	manual: {
		description: 'optional: use manually test format',
		'boolean': true,
		'default': false
	},
	log: {
		description: 'optional: display handler log info',
		'boolean': true,
		'default': false
	},
	QuoteTransformer: {
		description: 'Run QuoteTransformer tests'
	},
	ListHandler: {
		description: 'Run ListHandler tests'
	},
	ParagraphWrapper: {
		description: 'Run ParagraphWrapper tests'
	},
	PreHandler: {
		description: 'Run PreHandler tests'
	},
	TokenStreamPatcher: {
		description: 'Run TokenStreamPatcher tests'
	},
	BehaviorSwitchHandler: {
		description: 'Run BehaviorSwitchHandler tests'
	},
	SanitizerHandler: {
		description: 'Run SanitizerHandler tests'
	}
});

function selectTestType(commandLine, manager, handler) {
	var iterator = 1;
	if (commandLine.timingMode) {
		iterator = 10000;
	}
	while (iterator--) {
		if (commandLine.manual) {
			manager.unitTest(handler, commandLine);
		} else {
			manager.wikitextTest(handler, commandLine);
		}
	}
}

function runTests() {
	var argv = opts.argv;

	if (Util.booleanOption(argv.help)) {
		opts.showHelp();
		return;
	}

	if (!argv.inputFile) {
		console.log("must specify [--manual] [--log] --TransformerName --inputFile /path/filename");
		console.log('type: "node bin/transformerTests.js --help" for more information');
		return;
	}

	var mockEnv;
	if (argv.log) {
		mockEnv = {
			log: MockTTM.prototype.log
		};
	} else {
		mockEnv = {
			log: () => {} // this disables detailed logging
		};
	}

	var manager = new MockTTM(mockEnv, {});

	if (argv.timingMode) {
		console.log("\nTiming Mode enabled, no console output expected till test completes\n");
	}

	var startTime = Date.now();

	if (argv.QuoteTransformer) {
		var qt = new QuoteTransformer(manager, {});
		selectTestType(argv, manager, qt);
	} else if (argv.ListHandler) {
		var lh = new ListHandler(manager, {});
		selectTestType(argv, manager, lh);
	} else if (argv.ParagraphWrapper) {
		var pw = new ParagraphWrapper(manager, {});
		selectTestType(argv, manager, pw);
	} else if (argv.PreHandler) {
		var ph = new PreHandler(manager, {});
		selectTestType(argv, manager, ph);
	} else if (argv.TokenStreamPatcher) {
		var tsp = new TokenStreamPatcher(manager, {});
		selectTestType(argv, manager, tsp);
	} else if (argv.BehaviorSwitchHandler) {
		var bsh = new BehaviorSwitchHandler(manager, {});
		selectTestType(argv, manager, bsh);
	} else if (argv.SanitizerHandler) {
		var sh = new SanitizerHandler(manager, {});
		selectTestType(argv, manager, sh);
	} else {
		console.log("No valid TransformerName was specified");
	}

	var totalTime = Date.now() - startTime;
	console.log('Total transformer execution time = ' + totalTime + ' milliseconds');
	console.log('Total time processing tokens     = ' + manager.tokenTime + ' milliseconds');
}

runTests();
